{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sundaybest3/Spring2024/blob/main/Corpus/NLP01_ana.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Project #1: Creating a Word Frequency List**\n",
        "\n",
        "bold체 할 때 **\n"
      ],
      "metadata": {
        "id": "_5QpFK22oG5f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Provide the text\n",
        "t1 = \"Your text goes here. It can be any length and contain any words.\""
      ],
      "metadata": {
        "id": "mxRDUTJsrxmd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "words하면 세로로, 마지막 줄에 입력했을 때만 출력\n",
        "print(words)하면 가로로, 아무데나 입력해도 출력"
      ],
      "metadata": {
        "id": "EIfitG1UvZFX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Clean and split the text into words\n",
        "\n",
        "# Convert to lowercase and split based on spaces\n",
        "word = t1.lower()\n",
        "words = word.split()\n",
        "print(words)\n",
        "words"
      ],
      "metadata": {
        "id": "BYlesDV9_Njv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "re.sub(a, b, text): substitute a with b in data(=text)\n",
        ". regular expression\n",
        "```\n",
        "re.sub(r'[^\\w\\s]', '', text)\n",
        "```\n",
        "+ substitute all characters that are not word characters ('\\w' = alphanumeric characters) or whitespace characters ('\\s') with an empty string.\n",
        "+ r: raw string makes the expression clearer and avoids the need to escape the backslashes.\n",
        "\n",
        "+ Backslash: '\\\\\\\\' => r'\\\\'"
      ],
      "metadata": {
        "id": "MK2EOLMCs1Ti"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Remove punctuation using regex (keep only words and spaces)\n",
        "#\n",
        "cleanwords = re.sub(r'[^\\w\\s]', '', text)\n",
        "\n",
        "# Convert to lowercase and split based on spaces\n",
        "word = cleanwords.lower()\n",
        "words = word.split()\n",
        "words"
      ],
      "metadata": {
        "id": "TyW3MiLysD6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Sort the list of words alphabetically\n",
        "sorted_words = sorted(words)\n",
        "\n",
        "#print(sorted(words))\n",
        "\n",
        "print(sorted_words)"
      ],
      "metadata": {
        "id": "iWAuffbUBZ6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Getting frequency"
      ],
      "metadata": {
        "id": "ZO35iY3zBuwY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The pattern r'\\b\\w+\\b' below is a regular expression:\n",
        "\n",
        "+ \\b is a word boundary. This part of the pattern specifies that we are looking for whole words, not substrings within words. For example, in the string \"catapult\", \\b would match the positions at the start and end of the word, but not around 'cat'.\n",
        "\n",
        "+ \\w+ matches one or more word characters (letters, digits, or underscores). **In regular expressions, \\w is a shorthand for [a-zA-Z0-9_].**\n",
        "+ So, \\b\\w+\\b effectively matches whole words — sequences of one or more word characters surrounded by word boundaries.\n",
        "+ the regular expression r'\\b\\w+\\b' without the raw string notation would become '\\\\\\b\\\\\\w+\\\\\\b'."
      ],
      "metadata": {
        "id": "OawlwVMKCmSa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [1] Using collections library"
      ],
      "metadata": {
        "id": "K_cnJ2KlwGwb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "19KEq1BjoDl_"
      },
      "outputs": [],
      "source": [
        "# Step 1: Import the necessary library\n",
        "from collections import Counter\n",
        "import re\n",
        "\n",
        "# Step 2: Provide the text\n",
        "text = \"Your text goes here. It can be any length and contain any words.\"\n",
        "\n",
        "# Step 3: Clean and split the text into words\n",
        "# Convert to lowercase and use regex to filter out non-word characters\n",
        "# re.findall(pattern, string)\n",
        "\n",
        "words = re.findall(r'\\b\\w+\\b', text.lower())\n",
        "\n",
        "# Step 4: Count the frequency of each word\n",
        "frequency = Counter(words)\n",
        "\n",
        "# Step 5: Display the frequency list\n",
        "for word, count in frequency.items():\n",
        "    print(f\"{word}: {count}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Display the frequency list\n",
        "for word, count in frequency.most_common():\n",
        "    print(f\"{word}: {count}\")"
      ],
      "metadata": {
        "id": "yuCyJABEFeZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [2] Using nltk (same process)"
      ],
      "metadata": {
        "id": "dLFmc5gKvuZS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk # Step 1: install nltk"
      ],
      "metadata": {
        "id": "4evXRv5RvxEM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Provide the text\n",
        "text = \"Your text goes here. It can be any length and contain any words.\""
      ],
      "metadata": {
        "id": "RslV2NVlv2uC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from nltk.probability import FreqDist\n",
        "\n",
        "# Step 3: Clean and split the text into words\n",
        "# Convert to lowercase and use regex to filter out non-word characters\n",
        "words = re.findall(r'\\b\\w+\\b', text.lower())\n",
        "\n",
        "# Step 4: Count the frequency of each word using FreqDist from nltk\n",
        "frequency = FreqDist(words)\n",
        "\n",
        "# Step 5: Display the frequency list\n",
        "for word, count in frequency.items():\n",
        "    print(f\"{word}: {count}\")\n"
      ],
      "metadata": {
        "id": "_iszLochv0oz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Frequency list to save as a dataframe > csv file (Excel worksheet) on colab folder\n",
        "\n",
        "+ [sample texts from online Lingua.com](https://lingua.com/english/reading/#exercises)\n",
        "+ [sample for practice](https://lingua.com/english/reading/days/)"
      ],
      "metadata": {
        "id": "dwW8j342E-ES"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Provide the text\n",
        "text = \"\"\"\n",
        "Days of the week\n",
        "There are seven days of the week, or uniquely named 24-hour periods designed to provide scheduling context and make time more easily measureable. Each of these days is identifiable by specific plans, moods, and tones.\n",
        "\n",
        "Monday is viewed by many to be the \"worst\" day of the week, as it marks the return to work following the weekend, when most full-time employees are given two days off. Most students attend school in the morning and return home in the afternoon (usually from about eight until three or seven until two), and most workers go to work in the morning and return home in the evening (usually from nine to five or eight to four).\n",
        "\n",
        "Tuesday is the second day of the week, and is in many ways similar to Monday. Not a whole lot of changes, schedule-wise, between Tuesday and Monday; most individuals go to school or work and return home to watch television, play video games, make plans with friends, spend time with family, read, or engage in a similar leisure-related activity.\n",
        "\n",
        "Wednesday is the third day of the week, and serves as the \"middle\" of the work week; some individuals refer to Wednesday as \"hump day,\" as once its workday is complete, employees will have passed the work-week \"hump,\" and will be on the downturn, as only two days on the job will remain in the week.\n",
        "\n",
        "Thursday is the fourth day of the week, and is viewed favorably by many, as it's rather close to the end of the work week.\n",
        "\n",
        "Friday is the fifth day of the week, and marks the end of the workweek and school-week for the vast majority of employees and students. By Friday afternoon/evening, most students/workers cannot wait to leave and go home, as they won't have to report back to school/work until Monday.\n",
        "\n",
        "Saturday is perhaps the most highly regarded day of the week. Because Sunday follows it (and there is presumably no work or school to attend, for most individuals), everyone is free to stay out (or awake) until late at night, having fun with plans or other leisure-related activities. To be sure, Saturday is generally thought of as a day to partake in hobbies that couldn't otherwise be enjoyed during the regular week.\n",
        "\n",
        "Sunday is the final day of the week, and is used by most as a day of rest. Fewer late-night plans are made on Sundays, compared to Saturdays, as most individuals have to wake up for work or school on Monday morning.\"\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "8E5OSFaYHDMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Import the necessary library\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "import re\n",
        "\n",
        "# Step 3: Clean and split the text into words\n",
        "# Convert to lowercase and use regex to filter out non-word characters\n",
        "# re.findall(pattern, string)\n",
        "\n",
        "words = re.findall(r'\\b\\w+\\b', text.lower())\n",
        "\n",
        "# Step 4: Count the frequency of each word\n",
        "frequency = Counter(words)\n",
        "\n",
        "# Convert the frequency data to a DataFrame\n",
        "df = pd.DataFrame(frequency.most_common(), columns=['Word', 'Frequency'])\n",
        "\n",
        "# Display the DataFrame\n",
        "print(df)\n",
        "\n",
        "# Save the DataFrame as a CSV file\n",
        "df.to_csv('word_frequency.csv', index=False)"
      ],
      "metadata": {
        "id": "L-jS_yLwFD4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remove '24' (number words)  \n",
        "Current text: **text** (variable name)"
      ],
      "metadata": {
        "id": "WFnZxoE0ISBn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from collections import Counter\n",
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "# Clean and split the text into words\n",
        "words = re.findall(r'\\b\\w+\\b', text.lower())\n",
        "\n",
        "# Filter out '24' from the list of words\n",
        "filtered_words = [word for word in words if not word.isdigit()]\n",
        "\n",
        "# Count the frequency of each word\n",
        "frequency = Counter(filtered_words)\n",
        "\n",
        "# Convert the frequency data to a DataFrame\n",
        "df = pd.DataFrame(frequency.most_common(), columns=['Word', 'Frequency'])\n",
        "\n",
        "# Display the DataFrame\n",
        "print(df)\n",
        "\n",
        "# Save the DataFrame as a CSV file\n",
        "df.to_csv('word_frequency.csv', index=False)"
      ],
      "metadata": {
        "id": "vOTIgk3oIU9x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## File to download\n",
        "\n",
        "+ File location: '\\content\\filename.csv' (colab folder on the left panel)\n",
        "+ Or using codes"
      ],
      "metadata": {
        "id": "RRlY3UbNGXnz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Provide a download link (specific to Google Colab)\n",
        "from google.colab import files\n",
        "\n",
        "# To download the file, remove the # before the code below\n",
        "# files.download('/content/word_frequency.csv')"
      ],
      "metadata": {
        "id": "6b96bAEJGU8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Allow users to paste text: Using input function\n",
        "\n",
        "input()"
      ],
      "metadata": {
        "id": "vjXc6NyyJw-P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "id": "oCUvYSluKumB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A. Gradio APP #1"
      ],
      "metadata": {
        "id": "BesPw3jQOdoP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from collections import Counter\n",
        "\n",
        "#함수 정의는 def\n",
        "def process_text(text, sorting_option):\n",
        "    words = text.split()\n",
        "\n",
        "    # Count word frequencies\n",
        "    word_counts = Counter(words)\n",
        "\n",
        "    # Sort words based on the selected option\n",
        "    if sorting_option == 'alphabetically':\n",
        "        sorted_words = sorted(word_counts.items(), key=lambda x: x[0])\n",
        "    elif sorting_option == 'by_frequency':\n",
        "        sorted_words = sorted(word_counts.items(), key=lambda x: x[1], reverse=True)\n",
        "    else:\n",
        "        sorted_words = word_counts.items()\n",
        "\n",
        "    # Get the top 5 words with their frequencies\n",
        "    top_5_words = sorted_words[:5]\n",
        "\n",
        "    # Format the top 5 words and frequencies as a string\n",
        "    top_5_string = \"\\n\".join([f\"Word: {word}, Frequency: {freq}\" for word, freq in top_5_words])\n",
        "\n",
        "    return top_5_string\n",
        "\n",
        "#Gradio\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=process_text,\n",
        "    inputs=[gr.Textbox(\"text\", label=\"Paste Text Here\"),\n",
        "            gr.Radio([\"alphabetically\", \"by_frequency\", \"none\"], label=\"Select Sorting Option\")],\n",
        "    outputs=gr.Textbox(label=\"Top 5 Words with Frequencies\")\n",
        ")\n",
        "\n",
        "iface.launch(share=True)\n"
      ],
      "metadata": {
        "id": "hh4XOqEOOd6F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## B. Gradio App #2"
      ],
      "metadata": {
        "id": "ENKl4V0QPRFS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown The entire frequency list to display\n",
        "\n",
        "import gradio as gr\n",
        "from collections import Counter\n",
        "\n",
        "def process_text(text, sorting_option):\n",
        "    words = text.split()\n",
        "\n",
        "    # Count word frequencies\n",
        "    word_counts = Counter(words)\n",
        "\n",
        "    # Sort words based on the selected option\n",
        "    if sorting_option == 'alphabetically':\n",
        "        sorted_words = sorted(word_counts.items(), key=lambda x: x[0])\n",
        "    elif sorting_option == 'by_frequency':\n",
        "        sorted_words = sorted(word_counts.items(), key=lambda x: x[1], reverse=True)\n",
        "    else:\n",
        "        sorted_words = word_counts.items()\n",
        "\n",
        "    # Get the top 5 words with their frequencies\n",
        "    top_5_words = sorted_words\n",
        "\n",
        "    # Format the top 5 words and frequencies as an HTML table\n",
        "    table_html = \"<table style='width:100%'><tr><th>Word</th><th>Frequency</th></tr>\"\n",
        "    for word, freq in top_5_words:\n",
        "        table_html += f\"<tr><td>{word}</td><td>{freq}</td></tr>\"\n",
        "    table_html += \"</table>\"\n",
        "\n",
        "    return table_html\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=process_text,\n",
        "    inputs=[gr.Textbox(\"text\", label=\"Paste Text Here\"),\n",
        "            gr.Radio([\"alphabetically\", \"by_frequency\", \"none\"], label=\"Select Sorting Option\")],\n",
        "    outputs=gr.HTML(label=\"Top 5 Words with Frequencies\")\n",
        ")\n",
        "\n",
        "iface.launch(share=True)\n"
      ],
      "metadata": {
        "id": "Pv7qxfjEPRaD",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gradio APP#3"
      ],
      "metadata": {
        "id": "rpnpMi2LeSV0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Top 3 to display and csv file to download\n",
        "import gradio as gr\n",
        "from collections import Counter\n",
        "import string\n",
        "import csv\n",
        "import io\n",
        "\n",
        "def process_text(text, sorting_option):\n",
        "    # Remove punctuation from the input text\n",
        "    translator = str.maketrans('', '', string.punctuation)\n",
        "    text = text.translate(translator)\n",
        "\n",
        "    words = text.split()\n",
        "\n",
        "    # Count word frequencies\n",
        "    word_counts = Counter(words)\n",
        "\n",
        "    # Sort words based on the selected option\n",
        "    if sorting_option == 'alphabetically':\n",
        "        sorted_words = sorted(word_counts.items(), key=lambda x: x[0])\n",
        "    elif sorting_option == 'by_frequency':\n",
        "        sorted_words = sorted(word_counts.items(), key=lambda x: x[1], reverse=True)\n",
        "    else:\n",
        "        sorted_words = word_counts.items()\n",
        "\n",
        "    # Get the top 5 words with their frequencies\n",
        "    top_5_words = sorted_words\n",
        "\n",
        "    # Format the top 5 words and frequencies as an HTML table\n",
        "    table_html = \"<table style='width:100%'><tr><th>Word</th><th>Frequency</th></tr>\"\n",
        "    for word, freq in top_5_words:\n",
        "        table_html += f\"<tr><td>{word}</td><td>{freq}</td></tr>\"\n",
        "    table_html += \"</table>\"\n",
        "\n",
        "    # Create a CSV file\n",
        "    csv_data = []\n",
        "    for word, freq in top_5_words:\n",
        "        csv_data.append([word, freq])\n",
        "\n",
        "    # Write CSV data to a string buffer\n",
        "    csv_buffer = io.StringIO()\n",
        "    csv_writer = csv.writer(csv_buffer)\n",
        "    csv_writer.writerow([\"Word\", \"Frequency\"])\n",
        "    csv_writer.writerows(csv_data)\n",
        "    csv_buffer.seek(0)\n",
        "\n",
        "    # Create a download link for the CSV file\n",
        "    csv_download_link = f\"<a href='data:application/csv;charset=utf-8,{csv_buffer.getvalue()}' download='word_frequencies.csv'>Download CSV</a>\"\n",
        "\n",
        "    # Wrap the table in a div with a fixed height and scrolling\n",
        "    div_with_scroll = f\"<div style='height: 200px; overflow-y: scroll;'>{table_html}</div>\"\n",
        "\n",
        "    return div_with_scroll, csv_download_link\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=process_text,\n",
        "    inputs=[gr.Textbox(\"text\", label=\"Paste Text Here\"),\n",
        "            gr.Radio([\"alphabetically\", \"by_frequency\", \"none\"], label=\"Select Sorting Option\")],\n",
        "    outputs=[gr.HTML(label=\"Top 5 Words with Frequencies\"), gr.HTML(label=\"Download CSV\")]\n",
        ")\n",
        "\n",
        "iface.launch(share=True)\n"
      ],
      "metadata": {
        "id": "ojfeMe9BWwG4",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "App running on Hugginface [APP link](https://huggingface.co/spaces/MK-316/freqlist)\n",
        "\n",
        "\n",
        "The End"
      ],
      "metadata": {
        "id": "3IvMrSWLeWSi"
      }
    }
  ]
}