{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sundaybest3/Spring2024/blob/main/Corpus/TTR-and-lemmatization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üåø Topics:\n",
        "\n",
        "## 1. **Type vs. Token**\n",
        "## 2. Lexical Diversity measures (10 types)"
      ],
      "metadata": {
        "id": "X1fv4aZ0B68x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "myword=\"sample\""
      ],
      "metadata": {
        "id": "Rc8vBbZuglSM"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "myword=[\"sample\", \"6\",\"apple\"]\n",
        "#ÎåÄÍ¥ÑÌò∏Îäî Î¶¨Ïä§Ìä∏ ÎßåÎì§Í∏∞ - Í∑∏Îü¨Î©¥ Îã®Ïñ¥Î≥ÑÎ°ú lenÏùÑ Ïù∏ÏãùÌï®."
      ],
      "metadata": {
        "id": "o_kKQJOQh0m1"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "myword[0]"
      ],
      "metadata": {
        "id": "UWu-DDAriGPv",
        "outputId": "12116aaf-7c96-4139-9e7b-23bdb79695a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'sample'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(myword)"
      ],
      "metadata": {
        "id": "zo2arF6uiPc6",
        "outputId": "f5848351-eb7d-41b7-fb57-9551c6b49cac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "myword[-3:]"
      ],
      "metadata": {
        "id": "xeTYzkLKgtU3",
        "outputId": "0aa8b4e4-ef2f-4918-8b39-30e25122352f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ple'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "myword[3:]"
      ],
      "metadata": {
        "id": "NHS5VOfehq9A",
        "outputId": "a87d1dd9-f372-4ceb-c4cf-f61578853e98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ple'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(myword)"
      ],
      "metadata": {
        "id": "BBfYU_KPg6NN",
        "outputId": "226cbef3-ccff-462b-bcf4-f9fbc60a32f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(myword)\n",
        "print(len(myword))"
      ],
      "metadata": {
        "id": "vH40Ynq2hFJB",
        "outputId": "1a96ecf0-cb6c-403d-82ce-6c897d960686",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5-QRTK4hhUx_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1. Type vs. Token\n",
        "\n",
        "Example: A cat is chasing a mouse.\n",
        "\n",
        "+ Tokens: Tokens are often words, but they can also include punctuation, numbers, and other characters depending on the analysis. Simply put, tokens are the total number of words in a given text.\n",
        "\n",
        "  + 6 tokens in the given example\n",
        "\n",
        "+ Types: A type is the unique form of a token, disregarding its frequency of occurrence.\n",
        "\n",
        "  + 5 types in the given example."
      ],
      "metadata": {
        "id": "QuJHFaewBq5n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[text samples from Aesop fables](https://aesopsfables.org/)"
      ],
      "metadata": {
        "id": "QKFZ5TxMP5ue"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"An ant went to a Mistic-fountain.\"\n",
        "len(text)\n",
        "#lenÏùÄ spaceÎèÑ Ìè¨Ìï®Ìï®."
      ],
      "metadata": {
        "id": "cxO7aH8JQlXy",
        "outputId": "91743d60-c695-43fc-f762-3f5ab109b2fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "33"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **text.split()** # split string by space\n",
        "textÎûÄ textÎ°ú Ï†ÄÏû•Ìïú Î≥ÄÏàòÎ•º ÎßêÌï®."
      ],
      "metadata": {
        "id": "1yjXhWTJQ6TX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "step1 = text.split()\n",
        "#Í¥ÑÌò∏Ïóê ÎùÑÏñ¥Ïì∞Í∏∞Î•º ÏûÖÎ†•ÌïòÎ©¥ Îã®Ïñ¥ Îã®ÏúÑÎ°ú split Ìï¥Ï§ÄÎã§.\n",
        "print(step1)\n",
        "len(step1)"
      ],
      "metadata": {
        "id": "1pc8WHWwQkrp",
        "outputId": "55326dd1-2830-478f-b9b8-130543045a80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'text' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-afa31f5b8a0c>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstep1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#Í¥ÑÌò∏Ïóê ÎùÑÏñ¥Ïì∞Í∏∞Î•º ÏûÖÎ†•ÌïòÎ©¥ Îã®Ïñ¥ Îã®ÏúÑÎ°ú split Ìï¥Ï§ÄÎã§.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'text' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "step2 = text.split(\".\") # delimiter here is '.'\n",
        "#Î¨∏Ïû•ÏúºÎ°ú ÎÇòÎàÑÍ≥† Ïã∂ÏùÑ ÎïåÎäî \"ÎßàÏπ®Ìëú\"Î°ú Íµ¨Î∂Ñ, Í∑∏Îü¨Î©¥ Î¨∏Ïû• Îã®ÏúÑÎ°ú ÎÇòÎàÑÏñ¥Ïßê.\n",
        "print(step2)"
      ],
      "metadata": {
        "id": "M_qkU6FwREHI",
        "outputId": "af460d79-3d28-43b8-809b-4d9afda28af8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['An ant went to a Mistic-fountain', '']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text=input()\n",
        "print(\"Number of strings: \",len(text))\n",
        "words = text.split()\n",
        "print(\"Number of words: \",len(words))\n",
        "sents=text.split(\".\")\n",
        "print(\"Number of sentences: \",len(sents))\n",
        "\n"
      ],
      "metadata": {
        "id": "xyCo6qZ1kxVg",
        "outputId": "607083b4-4d05-402c-f1e0-95505c868530",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"An ant went to a Mistic-fountain.\"\n",
            "Number of strings:  35\n",
            "Number of words:  6\n",
            "Number of sentences:  2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using a longer text"
      ],
      "metadata": {
        "id": "UNpznL4oSIGp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This includes all characters: letters, numbers, spaces, punctuation marks, and special characters.\n",
        "\n",
        "text = \"\"\"\n",
        "An ant went to a fountain to quench his thirst and, tumbling in, was almost drowned. But a dove that happened to be sitting on a neighboring tree saw the ant's danger and, plucking off a leaf, let it drop into the water before him. The ant mounting upon it, was presently wafted safely ashore.\n",
        "Just at that time, a fowler was spreading his net and was in the act of ensnaring the dove, when the ant, perceiving his object, bit his heel. The start this gave the man made him drop his net and the dove, aroused to a sense of her danger, flew safely away.\n",
        "\"\"\"\n",
        "#''' '''ÎèÑ Í¥úÏ∞ÆÎã§. \"\"\"Îäî Ï§ÑÏù¥ Î∞îÎÄåÏñ¥ÎèÑ ÏÉÅÍ¥ÄÏóÜÎã§.\n",
        "print(\"Number of strings: \", len(text))"
      ],
      "metadata": {
        "id": "nrIqszf5Pj1u",
        "outputId": "2cbb5c12-f874-4d8f-9079-74683a887173",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of strings:  554\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = text.split()\n",
        "len(tokens)\n",
        "#spaceÎã®ÏúÑÎ°ú ÎÇòÎàà Í≤É = Îã®Ïñ¥"
      ],
      "metadata": {
        "id": "12i5q8r6QhcX",
        "outputId": "c2cee776-7667-46a1-e63a-c832cda330ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "107"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "types = set(tokens)\n",
        "#set()=count unique strings.\n",
        "len(types)\n"
      ],
      "metadata": {
        "id": "gVRl7ynYShZr",
        "outputId": "2b6864fd-82ce-4f77-c199-3034fdc1a511",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "76"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a1=\"banana, apple, apple, banana, grapes\"\n",
        "words=a1.split(\", \")\n",
        "set(words)"
      ],
      "metadata": {
        "id": "fdzGCEeamO86",
        "outputId": "5235dc37-35db-461d-812e-2383e8dfca1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'apple', 'banana', 'grapes'}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define a function"
      ],
      "metadata": {
        "id": "l0FsA9B5TPgW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def count_types_and_tokens(text):\n",
        "    tokens = text.split()\n",
        "    types = set(tokens)\n",
        "    return len(types), len(tokens)\n",
        "#Ìï®ÏàòÎ•º Ï†ïÏùòÌï† Îïå Ïì∞Îäî Í≤É, Ï§ÑÏùÑ ÎßûÏ∂îÏñ¥Ïïº Ìï®.: Î∂ôÏù¥Í∏∞"
      ],
      "metadata": {
        "id": "IVV1N3KjPuwD"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count_types_and_tokens(text)"
      ],
      "metadata": {
        "id": "aFWjnp9MniGe",
        "outputId": "353a17d9-6975-43fc-f241-aa20e6d2a5a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(76, 107)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Hiding code\n",
        "# Example text\n",
        "\n",
        "num_types, num_tokens = count_types_and_tokens(text)\n",
        "print(\"Number of types:\", num_types)\n",
        "print(\"Number of tokens:\", num_tokens)\n",
        "#TTR ÎßåÎìúÎäî Î∞©Î≤ï Type-Token Ratio"
      ],
      "metadata": {
        "id": "-06hNP2eTLdG",
        "outputId": "7b487287-c0f9-42b3-b8d8-dc321b6455a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of types: 76\n",
            "Number of tokens: 107\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lemmatization\n",
        "\n",
        "+ lemma: a dictionary form or base form of a set of words.\n",
        "+ example: 'run, runs, running, ran' => 'run'\n",
        "\n",
        "We will use {nltk} modules"
      ],
      "metadata": {
        "id": "NQXlTrHOTYBv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "metadata": {
        "id": "BkZIe6KlTzdi",
        "outputId": "5b613053-1e06-452d-ea5c-ea9c83ed94c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ÏûÑÌè¨Ìä∏Îäî ÌÉùÎ∞∞ Ïó¥Í∏∞ ÏõåÎìúÎÑ∑Î†àÎßàÌÉÄÏù¥Ï†ÄÎäî ÎèÑÍµ¨\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import wordnet\n",
        "\n",
        "# Download the WordNet resource (if not already downloaded)\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "E8HhAfXZT_Xt",
        "outputId": "8198af57-91c9-4794-84ba-60352b8e2b83",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The function below, get_wordnet_pos, is designed to map the part-of-speech (POS) tags provided by NLTK's pos_tag function to the format that is recognized by the WordNet Lemmatizer, which is part of the NLTK library. This mapping is essential for accurate lemmatization, as it allows the lemmatizer to understand the grammatical category of each word."
      ],
      "metadata": {
        "id": "pBsUOddJWRoa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define get_wordnet_pos(word)\n",
        "# pos means part of speech\n",
        "\n",
        "def get_wordnet_pos(word):\n",
        "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
        "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
        "    tag_dict = {\"J\": wordnet.ADJ,\n",
        "                \"N\": wordnet.NOUN,\n",
        "                \"V\": wordnet.VERB,\n",
        "                \"R\": wordnet.ADV}\n",
        "\n",
        "    return tag_dict.get(tag, wordnet.NOUN)"
      ],
      "metadata": {
        "id": "asSvbbChUMf2"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"The cats are running faster than the dogs\""
      ],
      "metadata": {
        "id": "65oy83YqUriA"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the WordNet lemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Tokenize the sentence\n",
        "tokens = nltk.word_tokenize(sentence)\n",
        "\n",
        "# Lemmatization using POS tags\n",
        "lemmatized_output = [lemmatizer.lemmatize(word, get_wordnet_pos(word)) for word in tokens]\n",
        "\n",
        "print('Original Sentence:', sentence)\n",
        "print('Lemmatized Sentence:', ' '.join(lemmatized_output))"
      ],
      "metadata": {
        "id": "JlfD53I4UhpX",
        "outputId": "f7facae0-700e-47e6-fb89-dcb702c5efa5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Sentence: The cats are running faster than the dogs\n",
            "Lemmatized Sentence: The cat be run faster than the dog\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Lemmatization practice with our text"
      ],
      "metadata": {
        "id": "Hrc_6o_DU_MB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"\n",
        "An ant went to a fountain to quench his thirst and, tumbling in, was almost drowned. But a dove that happened to be sitting on a neighboring tree saw the ant's danger and, plucking off a leaf, let it drop into the water before him. The ant mounting upon it, was presently wafted safely ashore.\n",
        "Just at that time, a fowler was spreading his net and was in the act of ensnaring the dove, when the ant, perceiving his object, bit his heel. The start this gave the man made him drop his net and the dove, aroused to a sense of her danger, flew safely away.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "kvWYRRrOVFpY"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the WordNet lemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Tokenize the sentence\n",
        "tokens = nltk.word_tokenize(text)\n",
        "\n",
        "# Lemmatization using POS tags\n",
        "lemmatized_output = [lemmatizer.lemmatize(word, get_wordnet_pos(word)) for word in tokens]\n",
        "\n",
        "print('Original Sentence:', text)\n",
        "print('Lemmatized Sentence:', ' '.join(lemmatized_output))"
      ],
      "metadata": {
        "id": "mnFhi93IVMPg",
        "outputId": "f48de06d-fa10-443f-c612-2bbd9d6bc684",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Sentence: \n",
            "An ant went to a fountain to quench his thirst and, tumbling in, was almost drowned. But a dove that happened to be sitting on a neighboring tree saw the ant's danger and, plucking off a leaf, let it drop into the water before him. The ant mounting upon it, was presently wafted safely ashore.\n",
            "Just at that time, a fowler was spreading his net and was in the act of ensnaring the dove, when the ant, perceiving his object, bit his heel. The start this gave the man made him drop his net and the dove, aroused to a sense of her danger, flew safely away.\n",
            "\n",
            "Lemmatized Sentence: An ant go to a fountain to quench his thirst and , tumble in , be almost drown . But a dove that happen to be sit on a neighbor tree saw the ant 's danger and , pluck off a leaf , let it drop into the water before him . The ant mount upon it , be presently waft safely ashore . Just at that time , a fowler be spread his net and be in the act of ensnare the dove , when the ant , perceive his object , bit his heel . The start this give the man make him drop his net and the dove , arouse to a sense of her danger , flew safely away .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(lemmatized_output)"
      ],
      "metadata": {
        "id": "1IcWfn3LXX3C",
        "outputId": "031068c1-50f2-428a-e418-d91407403d39",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "124"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's compare text tokens, types, and lemmatized"
      ],
      "metadata": {
        "id": "q4L-fuHZXd1p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"\n",
        "An ant went to a fountain to quench his thirst and, tumbling in, was almost drowned. But a dove that happened to be sitting on a neighboring tree saw the ant's danger and, plucking off a leaf, let it drop into the water before him. The ant mounting upon it, was presently wafted safely ashore.\n",
        "Just at that time, a fowler was spreading his net and was in the act of ensnaring the dove, when the ant, perceiving his object, bit his heel. The start this gave the man made him drop his net and the dove, aroused to a sense of her danger, flew safely away.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "_E_UomUKYeLu"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = text.split(); print(len(tokens))\n",
        "print(len(lemmatized_output))"
      ],
      "metadata": {
        "id": "SqLZXVAXYiJa",
        "outputId": "dda34132-e867-47af-f184-8f072340fa22",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "107\n",
            "124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Types in the text order"
      ],
      "metadata": {
        "id": "H5u8BYYbagUH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'tokens' is already defined\n",
        "\n",
        "types_in_order = []\n",
        "seen = set()\n",
        "\n",
        "for token in tokens:\n",
        "    if token not in seen:\n",
        "        seen.add(token)\n",
        "        types_in_order.append(token)\n",
        "\n",
        "# Now 'types_in_order' contains unique elements from 'tokens' in the order they appear in the text\n"
      ],
      "metadata": {
        "id": "upt-2KK1aVpQ"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a dataframe with tokens, types_in_order, lemmatized_output\n",
        "\n",
        "print(len(tokens))\n",
        "print(len(types_in_order))\n",
        "print(len(lemmatized_output))"
      ],
      "metadata": {
        "id": "pYqm_ezLZtzP",
        "outputId": "a5d01e47-d2e8-42d9-81a2-0ebc70f41273",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "107\n",
            "76\n",
            "124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas\n",
        "#ÏóëÏÖÄÏûêÎ£åÎ•º Îã§Î£∞ Îïå Ïì∞ÏûÑ"
      ],
      "metadata": {
        "id": "Wqo2YtsBYIm-",
        "outputId": "257a8668-09cd-40b0-a646-1e588f0c9b32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming tokens, types_in_order, and lemmatized_output are already defined\n",
        "# and their lengths are 107, 76, 124 respectively\n",
        "#ÌåêÎã§Ïä§Î•º Í∞ÄÏ†∏ÏôÄÏÑú Îç∞Ïù¥ÌÑ∞ÌîÑÎ†àÏûÑÏùÑ ÎßåÎì§ Îïå ÏîÄ.\n",
        "# Extend types_in_order and tokens with 'None' to match the length of lemmatized_output\n",
        "types_in_order.extend([None] * (len(lemmatized_output) - len(types_in_order)))\n",
        "tokens.extend([None] * (len(lemmatized_output) - len(tokens)))\n",
        "\n",
        "# Create the DataFrame csv file\n",
        "df = pd.DataFrame({\n",
        "    'Tokens': tokens,\n",
        "    'Types': types_in_order,\n",
        "    'Lemmatized Output': lemmatized_output\n",
        "})\n",
        "\n",
        "df[1:21]\n",
        "#1Î∂ÄÌÑ∞ ÌïòÎäî Ïù¥Ïú†Îäî Ìï≠Î™©Î™ÖÏù¥ 0Ïù¥Í∏∞ ÎïåÎ¨∏"
      ],
      "metadata": {
        "id": "nlzdg1l4YMu8",
        "outputId": "46e99daf-d016-46db-db1f-8f36734bf783",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        }
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Tokens     Types Lemmatized Output\n",
              "1        ant       ant               ant\n",
              "2       went      went                go\n",
              "3         to        to                to\n",
              "4          a         a                 a\n",
              "5   fountain  fountain          fountain\n",
              "6         to    quench                to\n",
              "7     quench       his            quench\n",
              "8        his    thirst               his\n",
              "9     thirst      and,            thirst\n",
              "10      and,  tumbling               and\n",
              "11  tumbling       in,                 ,\n",
              "12       in,       was            tumble\n",
              "13       was    almost                in\n",
              "14    almost  drowned.                 ,\n",
              "15  drowned.       But                be\n",
              "16       But      dove            almost\n",
              "17         a      that             drown\n",
              "18      dove  happened                 .\n",
              "19      that        be               But\n",
              "20  happened   sitting                 a"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-97894945-b009-4826-8308-1079e87a82fa\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tokens</th>\n",
              "      <th>Types</th>\n",
              "      <th>Lemmatized Output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ant</td>\n",
              "      <td>ant</td>\n",
              "      <td>ant</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>went</td>\n",
              "      <td>went</td>\n",
              "      <td>go</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>to</td>\n",
              "      <td>to</td>\n",
              "      <td>to</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>a</td>\n",
              "      <td>a</td>\n",
              "      <td>a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>fountain</td>\n",
              "      <td>fountain</td>\n",
              "      <td>fountain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>to</td>\n",
              "      <td>quench</td>\n",
              "      <td>to</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>quench</td>\n",
              "      <td>his</td>\n",
              "      <td>quench</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>his</td>\n",
              "      <td>thirst</td>\n",
              "      <td>his</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>thirst</td>\n",
              "      <td>and,</td>\n",
              "      <td>thirst</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>and,</td>\n",
              "      <td>tumbling</td>\n",
              "      <td>and</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>tumbling</td>\n",
              "      <td>in,</td>\n",
              "      <td>,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>in,</td>\n",
              "      <td>was</td>\n",
              "      <td>tumble</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>was</td>\n",
              "      <td>almost</td>\n",
              "      <td>in</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>almost</td>\n",
              "      <td>drowned.</td>\n",
              "      <td>,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>drowned.</td>\n",
              "      <td>But</td>\n",
              "      <td>be</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>But</td>\n",
              "      <td>dove</td>\n",
              "      <td>almost</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>a</td>\n",
              "      <td>that</td>\n",
              "      <td>drown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>dove</td>\n",
              "      <td>happened</td>\n",
              "      <td>.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>that</td>\n",
              "      <td>be</td>\n",
              "      <td>But</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>happened</td>\n",
              "      <td>sitting</td>\n",
              "      <td>a</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-97894945-b009-4826-8308-1079e87a82fa')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-97894945-b009-4826-8308-1079e87a82fa button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-97894945-b009-4826-8308-1079e87a82fa');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-47d93961-24a7-4b37-9274-dab6b9707fb3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-47d93961-24a7-4b37-9274-dab6b9707fb3')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-47d93961-24a7-4b37-9274-dab6b9707fb3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df[1:21]\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"Tokens\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 18,\n        \"samples\": [\n          \"ant\",\n          \"went\",\n          \"and,\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Types\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"ant\",\n          \"happened\",\n          \"dove\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Lemmatized Output\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 17,\n        \"samples\": [\n          \"ant\",\n          \"go\",\n          \"quench\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TTR (Type-to-Token Ratio)"
      ],
      "metadata": {
        "id": "RRvfPCr7VEV_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have already calculated the number of types and tokens\n",
        "number_of_types = len(types)  # Number of unique words\n",
        "number_of_tokens = len(tokens)  # Total number of words\n",
        "\n",
        "# Calculate TTR\n",
        "TTR = number_of_types / number_of_tokens\n",
        "\n",
        "print(\"Type-Token Ratio (TTR):\", TTR)\n"
      ],
      "metadata": {
        "id": "eb9oBqo9cmNi",
        "outputId": "dbf6aa84-b660-434a-bbfa-a8160dad5bb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'types' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-b5f9a522aaec>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Assuming you have already calculated the number of types and tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnumber_of_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtypes\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Number of unique words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mnumber_of_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Total number of words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Calculate TTR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'types' is not defined"
          ]
        }
      ]
    }
  ]
}